{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb90ec2e083a3ae844fff9b103c3ba36",
     "grade": false,
     "grade_id": "cell-6453afbe0bdb6aa6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"logo-2020.png\" alt=\"frankfurt school hmi\" width=\"150\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e714f9bbd56102c68a1be74c375df63c",
     "grade": false,
     "grade_id": "cell-acb40d952bd1742d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "___\n",
    "# Machine Learning I.\n",
    "## Problem Set 1: Linear Regression (14 points total)\n",
    "\n",
    "### Instructions\n",
    "The graded portion of problem set 1 consists of one notebook:\n",
    "```\n",
    "ps1_nb1.ipynb\n",
    "```\n",
    "There are also two ungraded tutorials in the `Tutorials` folder, a quick introduction to Jupyter notebooks and a tutorial on numpy arrays:\n",
    "```\n",
    "t0-introduction-to-notebooks.ipynb\n",
    "t1-numpy_introduction.ipynb\n",
    "```\n",
    "Both are recommended. \n",
    "\n",
    "### Due Date\n",
    "* 27.JAN.2022 before 23:59:59 (CET)\n",
    "\n",
    "### Instructor\n",
    "* Prof. Dr. Gregory Wheeler ([gregorywheeler.org](http://gregorywheeler.org))\n",
    "\n",
    "---\n",
    "\n",
    "### Declare your collaborators\n",
    "You may work alone or in a group. The maximum group size is 4 people, including yourself. Each student must submit his or her own individual notebook. \n",
    "\n",
    "If you work in a group, use the next cell to enter the list of names (first, last) of your collaborators. \n",
    "~~~python\n",
    "# Example\n",
    "COLLABORATORS = ['Stu Dent', 'May Bee', 'Ki Val Storr']\n",
    "~~~\n",
    "You should also familiarize yourself with the collaboration policy on the course Canvas page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure your names are strings\n",
    "COLLABORATORS = ['Carla Weidner', 'Chaitanya Madduri', 'Jasmin Capka']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a9bf5e597f01ae32a50358f94c41f4c",
     "grade": false,
     "grade_id": "cell-b62ce31b7ef69ad4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "---\n",
    "## <i>Money cannot buy happiness. Or can it?</i>\n",
    "\n",
    "The populations of some countries are happier than other countries. In this exercise, you will investigate the relationship between a country's per capita GDP and its \"happiness score\".  Since 2012, the annual [World Happiness Report](https://worldhappiness.report/), published by the United Nations' [Sustainable Development Solutions Network](https://www.unsdsn.org/), asks people around the world how happy they are. The happiness score uses the [Cantril scale](https://news.gallup.com/poll/122453/understanding-gallup-uses-cantril-scale.aspx), which is a subjective scale constructed by asking respondents to imagine a ladder on which the best possible life for themselves receives the score of 10, the worst possible life a score of 0, and then are asked to rate their own lives on that scale between 0 and 10.  The questionaire is given to a representative sample of each country each year.\n",
    "\n",
    "We expect more individual wealth to correlate with higher happiness. But, how much of the variation in happiness is explained by individual wealth?  That is the question we will explore in outline.  The focus of this exercise is not your analysis per se, but the computational details behind fitting parameters of an ordinary least-squares (OLS) regression.\n",
    "\n",
    "There are three main tasks in this notebook.\n",
    "\n",
    " - PART A. Implement Gradient Descent to calculate the coefficients of a univariate linear regression\n",
    " - PART B. Use a built-in library to check your implementation in A and perform some analysis \n",
    " - PART C. Prepare data yourself and apply your model. \n",
    " \n",
    "You will be asked to write some code and also answer several questions about the model and data. The first step is to run the next cell to load the basic libraries we will use in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db0f5bcfa7d148b8b043c94b6c1aa54c",
     "grade": false,
     "grade_id": "cell-3683f8c3c14a645b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# import numpy and set up plotting parameters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2870f0024da25acfc8e8f0ca64ec5d5f",
     "grade": false,
     "grade_id": "cell-cda1152bfc9e0c0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# PART A - Gradient Descent\n",
    "\n",
    "## I. Loading and Formatting Data\n",
    "In the ps1 directory you will find the data set for problem 1, `ps1_data1.csv`. File loading methods vary depending on the format of the data file. This particular data set is a _comma-seperated text file_ (.csv), so we will use the numpy function `np.loadtxt` and specify that the columns are delimited by commas.\n",
    "\n",
    "Run the next cell to load `ps1_data1.csv` into a numpy array assigned to the variable `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('ps1_data1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13154cdb32ca2ebe8d049d6db3c98f45",
     "grade": false,
     "grade_id": "cell-3feec8c3b2a19f6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recall that numpy arrays are Python's standard datatype for computing with vectors, matrices, and tensors, and the numerical methods of numpy -- such as `np.dot` and `np.sum` -- are element-wise operations. Although there is also a Python matrix package designed specifically to do linear algebra operations, we will use numpy.\n",
    "\n",
    "(For those of you new to Python but who are familiar with linear algebra or with programming matrix operations in MATLAB, [this page](https://www.khanacademy.org/math/precalculus/precalc-matrices/multiplying-matrices-by-matrices/v/matrix-multiplication-intro) contains useful comparison between Python and MATLAB to help you get quickly up to speed.)\n",
    "\n",
    "You can confirm that data is a numpy array by checking its type, i.e. by excuting `type(data)`. It is also important to know about the dimensions of `data` -- that is, the number of rows (training examples) and the number of columns (features and target). This information is given by using the method `.shape`, i.e., by executing `data.shape`.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> You can insert a cell anywhere (+) and delete it (scissors) or any other cell that is not locked\n",
    "    \n",
    "<img src=\"ps_fig1.png\" alt=\"ps3_fig1\" width =\"100\"/>  \n",
    "\n",
    "However, before turning in your assignment, you should remove any cells you have added.  \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> To clear the output of your notebook and your local memory, you can restart the kernel and clear  â€œKernel >> Restart and Clear all Output\":\n",
    "\n",
    "<img src=\"ps_fig2.png\" alt=\"ps3_fig2\" width=\"250\"/> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99450070217c4af74daa6638446bac4a",
     "grade": false,
     "grade_id": "cell-61e93e897ed5317a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You should see that `data` has two columns. The first column is the feature $x$, <b>per Capita GDP</b> of each country in `data`, and the second column is the target $y$, the corresponding <b>Happiness index</b>. The number of rows denotes the number of training examples, which by convention is assigned to the variable `m`.\n",
    "\n",
    "In the next cell, you should complete the function `set_variables()` which will take an array as an argument and return three variables: `x` and `y` , each of which is itself an array; and `m`, an integer. When `set_variables()` is called specifically on `data`, the three variables are\n",
    "\n",
    "    x - the features of psl_data; i.e., the first column, per capita GDP\n",
    "    y - the target variable of psl_data; i.e., happiness index\n",
    "    m - the number of training examples in psl_data.\n",
    "\n",
    "<u>Your code should work on <b>any</b> two-column array</u>, not only on `data`.\n",
    "\n",
    "<div class=\"alert alert-info\"><b>Tip</b>: Remember that arrays in Python are 0-indexed.</div>\n",
    "\n",
    "\n",
    "\n",
    "### Completing Functions\n",
    "\n",
    "The next cell has a partially completed function, `set_variables()`.  Inside the code block, you will see two lines:\n",
    "\n",
    "~~~python\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "~~~\n",
    "\n",
    "To complete the function, you should delete both of these lines and replace the comment `# YOUR CODE HERE` with your line or lines of code.  The second line raises a  \"not implemented error\" and is included automatically to guard against accidentally submitting an incomplete assignment.  To pass the final validation, you must remove each of these errors from your functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76c6a6da1c3d078b4ec682f5e5915a4d",
     "grade": false,
     "grade_id": "setVariables",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def setVariables(data_array) :\n",
    "    \"\"\"\n",
    "    The function set_variables() is called on one argument:\n",
    "    \n",
    "        data_array := an np.array \n",
    "        \n",
    "    and returns three global variables:\n",
    "        x := the first column of data_array\n",
    "        y := the second column of the data_array\n",
    "        m := the number of rows of the data_array na\n",
    "    Your code should run on any two-column data_array.\n",
    "    \"\"\"\n",
    "    global x\n",
    "    global y\n",
    "    global m\n",
    "    \n",
    "    x = data_array[:,0]\n",
    "    y = data_array[:,1]\n",
    "    \n",
    "    m = data_array.shape[0] # without [0] this would return m and n\n",
    "    \n",
    "    \n",
    "    return x, y, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9cb5ee53d02a075c60b1a296dd0cca2",
     "grade": false,
     "grade_id": "cell-6a1a3dea65d20fa6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Test Cells\n",
    "The next three cells are test cells that will evaluate your implementation of `setVariables()`. You should run all three. (They will be run automatically when your notebook is graded.) Each of these cells has a line of code, which is a \"public\" test of your code, but there are also \"hidden\" tests of your code.  The public tests are designed to give you some initial feedback that you are on the right track. However, passing the public test is no guarantee that you will pass the private tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e68614f6e7d05c3d02efb5f852fe063",
     "grade": true,
     "grade_id": "setVariables-test1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"TEST CELL 1 for set_variables\"\"\"\n",
    "setVariables(data)\n",
    "assert x[34] == 1.870765686 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e69c74b0d093494cb379b3d2b82e4f09",
     "grade": true,
     "grade_id": "setVariable-test2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"TEST CELL 2 for set_variables\"\"\"\n",
    "setVariables(data)\n",
    "assert y[71] == 5.429999828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd3b769e852e1a10ea1f9f829c098984",
     "grade": true,
     "grade_id": "setVariable-test3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"TEST CELL 3 for m of set_variables\"\"\"\n",
    "setVariables(data)\n",
    "assert m < 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3802d09ac28c5cd087e01c7e3cc077dd",
     "grade": false,
     "grade_id": "cell-537ebf2ac6ef5737",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## II. Data Visualization \n",
    "The following block of code produces a basic scatterplot with a legend and title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff0e8850b80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# produce scatterplot\n",
    "\n",
    "plt.scatter(x,y, label=\"ps1_data1\")\n",
    "plt.title('2019 World Happiness by Country')\n",
    "plt.xlabel(r'Per Capita GPD')\n",
    "plt.ylabel(r'Happiness Score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2e03312c1967f7620840785cfcde404",
     "grade": false,
     "grade_id": "cell-ccc4359102f38e22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## III. Implementing Gradient Descent\n",
    "\n",
    "\n",
    "Now we will implement gradient descent to fit the **linear regression** parameters $\\boldsymbol{\\theta} = (\\theta_0,\\theta_1)$ to the data set, `data`.\n",
    "\n",
    "### Univariate Linear Regression\n",
    "\n",
    "A univariate linear regression has one _independent variable or regressor, x,_ which is called a _feature_ in machine learning. The _dependent variable_ or _target_ variable $y$, is the  true happiness score.  The goal is to fit a linear model to estimate or predict the value of $y$, happiness, as some linear function of $x$, per capita GDP. Specifically, the hypothesis $h(x; \\boldsymbol{\\theta})$ is determined by $\\boldsymbol{\\theta}$, a two-dimensional vector $\\boldsymbol{\\theta} = (\\theta_0,\\theta_1)$, and the single feature $ x_1$, such that $$h(x; \\boldsymbol{\\theta}) = \\theta_0 + \\theta_1x_1.$$\n",
    "\n",
    "\n",
    "To fit a model of this form to data, we need a way to pick values for $\\theta_0$ and $ \\theta_1$ that \"best fit\" the data. Intuitively, we want to select parameters that minimize the error of its estimates of the known values for $y$ in the training data. Specifying, we will use <b>residual squared error (RSS)</b> as the numeric measure of performance and <b>ordinary least squares</b> as the definition of \"best fit.\"  Defining the precise form of this minimization task is done by defining the optimization objective of the algorithm, which is the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90a98596f84aa30b4e6710f53fcf8d81",
     "grade": false,
     "grade_id": "cell-daf616dda72c96f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Optimization Objective\n",
    "\n",
    "The optimization objective of linear regression is to minimize the <b>residual sum of squares</b>, RSS,  \n",
    "\n",
    "$$RSS = \\sum_{i=1}^m (\\hat{\\epsilon}^{(i)})^2 = \\sum_{i=1}^{m} (y^{(i)} - (\\hat{\\theta}_0 + \\hat{\\theta}_1x^{(i)} ))^2$$\n",
    "\n",
    "where RSS is the standard <b>loss function</b> used for fitting linear regression models.  The <b>mean squared error</b> (MSE) is $\\frac{RSS}{m}$.  The cost function $J(\\boldsymbol{\\theta})$ we will minimize is\n",
    "\n",
    "$$J(\\boldsymbol{\\theta}) = \\frac{1}{2m}\\sum_{i=1}^m (h(x^{(i)}; \\boldsymbol{\\theta}) - y^{(i)})^2$$\n",
    "\n",
    "which is $\\frac{1}{2} * MSE$. \n",
    "\n",
    "The index $i$ ranges over the number of training examples, $m$, in `data`. Informally, the cost function $J$ applied to $\\begin{align} \\boldsymbol{\\theta} & = (\\hat{\\theta}_0,\\hat{\\theta}_1)\\end{align}$ assesses the \"cost\" of using particular values for $\\hat{\\theta}_0$ and $\\hat{\\theta}_1$ to fit a straight line to `data`, measured as mean squared-error loss, and the optimization problem is one of picking values for $\\hat{\\theta}_0$ and for $\\hat{\\theta}_1$ that makes those costs as close to zero as possible. Unpacking the right side of this equation further, for each training example $i$ (that is, for each $i$ of the $m$ rows of `data` ), a hypothesis $h$ parameterized by $\\boldsymbol{\\theta}$ looks at the feature $x$ of the $i$th training example, written $x^{(i)}$, and computes an estimate of the value of $y$ for this $i$th example, written $h(x^{(i)}; \\boldsymbol{\\theta})$. The total loss then is the average squared-error loss for all $m$ training examples.\n",
    "\n",
    "Specifically, the optimization objective is to minimize the cost function $J(\\boldsymbol\\theta)$, written as $\\min_{\\boldsymbol{\\theta}} J(\\boldsymbol\\theta)$. The fraction $\\frac{1}{2}$ and changing $(y - h)^2$ in RSS to $(h- y)^2$ are each mathematical conveniences that make the next step simplier and more intuitive, respectively. \n",
    "\n",
    "<div class=\"alert alert-info\"><b>Notation 1</b>: In frequentist statistics $\\boldsymbol{\\theta}$ is the true but unknown parameter and $\\hat{\\boldsymbol{\\theta}}$ is an estimate of that unknown parameter. In short, the <b>estimators</b> that we construct, manipulate, and evaluate all wear hats. But, since we never deal directly with \"true but unknown\" parameters, when the discussion turns to coding we drop the hat notation entirely. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7c99b265f04c1da228291a28c5bfe7c",
     "grade": false,
     "grade_id": "cell-0d2eb27e9dd8e26d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "### Implementation\n",
    "\n",
    "The adjustable parameters of a univariate regression model $h(x^{(i)}; \\boldsymbol{\\theta})$  are $\\theta_0$ and $\\theta_1$ in $\\mathbb{R}$-- or, if you did not read the previous remark about notation, $\\hat{\\theta}_0$ and $\\hat{\\theta}_1$ in $\\mathbb{R}$. The parameters $\\theta_0$ and $\\theta_1$  determine the $y$-intercept and slope, respectively.  They are the values that gradient descent changes to minimize the cost $J(\\boldsymbol{\\theta})$.\n",
    "\n",
    "There are a family of gradient descent algorithms. We will implement **batch gradient descent**. In batch gradient descent, at each iteration of the algorithm the values for the parameter vector $\\boldsymbol{\\theta}$ (should!) change  closer to the optimal values that realize the lowest cost $ J(\\boldsymbol\\theta)$.  \n",
    "\n",
    "<div class=\"alert alert-info\"><b>Notation 2</b>:  The actual optimal parameter values that minimizes $J$ are unknown.  If our discussion were to dwell on the difference between the actual parameters and our estimated parameters, then we'd be compelled to put hats on the estimated parameters to distinguish them from the actual parameters. Becoming comfortable with different conventions for notation is part of becoming a proficient data scientist.\n",
    "</div>\n",
    "\n",
    "\n",
    "At each step batch gradient descent **simultaneously updates** all parameters $ \\theta_j $: \n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}(h(x^{(i)}; \\boldsymbol{\\theta}) - y^{(i)})x^{(i)} \\quad \\mbox{simultaneous update of } \\theta_j, \\mbox{ for all }j.$$\n",
    "\n",
    "The next series of steps guides you through an implementation of gradient descent.\n",
    "\n",
    "___\n",
    "\n",
    "**Step 1**. Observe that there are two scalar parameters, $\\theta_0$ and $\\theta_1$, but only one feature in `data`. (Check the shape of `x` if you are unconvinced.) Since $\\theta_0$ is the y-intercept term, this is the same as if we multiplied $\\theta_0$ by 1, for each <i>m</i> entries. We say that $x_0$ = 1 is a **intercept term**, and we add intercept terms in such cases to ensure that feature vectors and parameter vectors are <b>comformable</b>.\n",
    "\n",
    "\n",
    "\n",
    "With this explanation in mind, add a column of 1's to the single column feature vector within data. This new row of ones is to accommodate the $y$-intercept parameter, $\\theta_0$.  \n",
    "\n",
    "Mathematically, you will have created a $(m, 2)$-matrix $X$ that is conformable with the vector $\\boldsymbol{\\theta}$:\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "1 & x^{(1)}\\\\\n",
    "1 & x^{(2)}\\\\\n",
    "1 & x^{(3)}\\\\\n",
    "\\vdots & \\vdots\\\\\n",
    "1 & x^{(m)}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The shape of the array `X` should be ($m$,2)\n",
    "\n",
    "\n",
    "The next step is to initialize a $(2,)$ array, called `theta` , which initializes the values for $\\theta_0$ and $\\theta_1$, respectively. \n",
    "\n",
    "\n",
    "Our gradient descent algorithm will update `theta` in order to minimize the cost function <i>J</i>.\n",
    "\n",
    "Running the next cell initializes the variables `X` and `theta` for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5626dd8bd68c1dd3344324c23bd310ab",
     "grade": false,
     "grade_id": "initialize_arrays",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initialize(data_array, init_theta0, init_theta1):\n",
    "    \"\"\"Initialize data and parameters for ps1_data1.csv\n",
    "    \n",
    "            data_array  - an (m,2) np.array\n",
    "            init_theta0 - float\n",
    "            init_theta1 - float\n",
    "        \n",
    "    and returns two global variables:\n",
    "        X     an (m,2) array: a column of 1s and the first column of data_array, where m\n",
    "              is the number of rows in data_array\n",
    "        theta a (2,) vector initialized to init_theta0 and init_theta_1\n",
    "    \n",
    "    Your function should work for any (m,2) array, formatted as ps1_data1.csv is wrt \n",
    "    feature column and target column, and any floats init_theta_0, init_theta1\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    theta = np.array([init_theta0, init_theta1])\n",
    "    \n",
    "    x, y, m = setVariables(data_array)\n",
    "    \n",
    "    X = np.c_[ np.ones(m), x ] #hstack - horizontal concatenation\n",
    "    return theta, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c8e6e310d29fea0d1f1bd7df5157aac",
     "grade": true,
     "grade_id": "initialize_arrays_test-1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the arrays with your function\n",
    "theta, X = initialize(data, 0.0,0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67d65430bcf1ea1943c93d31dd0fd8d1",
     "grade": false,
     "grade_id": "cell-30394b510bba058a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Question 1\n",
    "\n",
    "Suppose that in addition to \"<i>per capita GDP</i>\" ($x_1$) you also had the average \"<i>life expectancy</i>\" ($x_2$) for each country to use as features in a linear model to estimate each country's <i>happiness score</i>. \n",
    "\n",
    "Which of the following statements encode such a model? Select all and only that apply.\n",
    "\n",
    "* A) $h(\\boldsymbol{x}; \\boldsymbol{\\theta}) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2$\n",
    "* B) $h(\\boldsymbol{x}; \\boldsymbol{\\theta}) = \\theta_0 + \\theta_1x_1 + x_2$\n",
    "* C) $h(\\boldsymbol{x}; \\boldsymbol{\\theta}) = \\theta_0 + \\theta_1x_1 x_2$\n",
    "\n",
    "Suppose now you wish to initialize a data array and parameter vector for this model.  Which block of code could you use for this model?  (Assume as above that the last column of `data` is the target, $y$.)\n",
    "\n",
    "* D) \n",
    "~~~python\n",
    "# initialize data array\n",
    "X = np.ones((m, 3))\n",
    "X[:,1] = data[:,0]\n",
    "# initalize model\n",
    "theta = np.zeros(2)\n",
    "~~~\n",
    "\n",
    "* E) \n",
    "~~~python\n",
    "# initialize data array\n",
    "X = np.ones((m, 3))\n",
    "X[:,0] = data[:,0]\n",
    "X[:,1] = data[:,1]\n",
    "# initalize model\n",
    "theta = np.zeros(3)\n",
    "~~~\n",
    "\n",
    "* F) \n",
    "~~~python\n",
    "# initialize data array\n",
    "X = np.ones((m, 3))\n",
    "X[:,1] = data[:,0]\n",
    "X[:,2] = data[:,1]\n",
    "# initalize model\n",
    "theta = np.zeros(3)\n",
    "~~~\n",
    "\n",
    "From the list of possible answers `['A', 'B', 'C', 'D', 'E', 'F]` , record your answer or answers as a <b>list</b> in the next cell by completing the function `ans_one()`.  For example, if the possible answers were `['P','Q','R']` and you selected P and Q as the correct answers, then you would simply write:\n",
    "~~~python\n",
    "ans = ['P', 'Q']\n",
    "~~~\n",
    "in the function `ans_one()`.\n",
    "\n",
    "---\n",
    "\n",
    "### Q1 Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b8ecf4e123a6182ce1dc7bf17555fb4",
     "grade": false,
     "grade_id": "ans_one-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ans_one():\n",
    "    \"\"\" Returns a list of your answers.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :ans:  list\n",
    "        The list of your answers. Elements of :ans: are strings.\n",
    "    Returns\n",
    "    -------\n",
    "    :ans:\n",
    "    \"\"\"\n",
    "    \n",
    "    ans = ['A', 'F'] #!!!! E would work but not with A. \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31fc52274ff77896f4a8e8f66d3bfe3f",
     "grade": true,
     "grade_id": "ans_one-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell for ans_one()\n",
    "ans = ans_one()\n",
    "%run -i 'ans_format_test.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "432d65275004731a306416d3c1790b9f",
     "grade": false,
     "grade_id": "cell-98e89d3a79671865",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Step 2.** Compute the squared-error cost function from above:\n",
    "\\begin{align} \\frac{1}{2m}\\sum_{i=1}^m (h(x^{(i)}; \\boldsymbol{\\theta}) - y^{(i)})^2 \\end{align}\n",
    "\n",
    "The function `costJ(X, y, theta)` takes as arguments the (_m_, 2)-dimension features array, `X` ,the (_m_, 1)-dimension target column vector, `y`, and the initial two-element parameter vector `theta`.\n",
    "\n",
    "There are several ways to implement this code, but a good strategy is to break the operation down into several steps and implement those steps as separate lines of code. Here is one way to attack the problem in two lines of code.\n",
    "\n",
    "<u>First Line of Code</u>\n",
    "\n",
    "Setting aside the indices, notice the general form of the hypothesis: $$h(x; \\boldsymbol{\\theta}) = \\theta_0x_0 + \\theta_1x_1.$$ Our first operation, then, is to multiply each $x^{(i)}$ in the second column of X by $\\theta_1$ and to keep $\\theta_0$ as is, which is why we added a column of 1s to X above: that is, $\\begin{align} x_0 =  1\\end{align}$ for all _m_ training examples. Then, for each estimate you can subtract the corresponding values of $y$.  \n",
    "\n",
    "<div class=\"alert alert-info\"> <b>Hint</b>: We deliberately highlighted the dimensions of the arrays 'X' and â€˜thetaâ€™ because there is a nice result from matrix algebra. Let $\\boldsymbol{X}$ and $\\boldsymbol{\\theta}$ be:\n",
    "    \n",
    " $$\\boldsymbol{X} = \\begin{bmatrix} \n",
    " \t\t\t\t1 & x_1^{(1)}  \\\\ \n",
    "\t\t\t\t1 & x_1^{(2)}   \\\\ \n",
    "\t\t\t\t1 & x_1^{(3)}   \\\\ \n",
    "\t\t\t\t\\vdots & \\vdots \\\\\n",
    "\t\t\t\t1 & x_1^{(m)}  \n",
    "\t\t\t\\end{bmatrix}\n",
    "\t\t\t%\n",
    "\t\t\t\\quad\n",
    "\t\t\t%\n",
    "\t\t\t%\n",
    " \\boldsymbol{\\theta} = \\begin{bmatrix} \\theta_0 \\\\ \\theta_1\n",
    "\t\\end{bmatrix}$$\n",
    "    \n",
    "Then,    \n",
    "$$\\begin{bmatrix} \n",
    " \t\t\t\t1 \\\\\n",
    "\t\t\t\t1 \\\\\n",
    "\t\t\t\t\\vdots \\\\\n",
    "\t\t\t\t1\n",
    "\t\t   \\end{bmatrix}\n",
    "\\theta_0  +\n",
    "%\n",
    " \\begin{bmatrix} \n",
    " \t\t\t\tx_1^{(1)}  \\\\\n",
    "\t\t\t\tx_1^{(2)}  \\\\\n",
    "\t\t\t\t\\vdots \\\\\n",
    "\t\t\t\tx_1^{(m)} \n",
    "\t\t   \\end{bmatrix}\n",
    "\\theta_1\n",
    "= \n",
    "\\begin{bmatrix} \n",
    " \t\t\t\t\\theta_0 + \\theta_1x^{(1)} \\\\ \n",
    "\t\t\t\t\\theta_0 + \\theta_1x^{(2)} \\\\ \n",
    "\t\t\t\t\\vdots \\\\\n",
    "\t\t\t\t\\theta_0 + \\theta_1x^{(m)} \\\\ \n",
    "\t\t\t\\end{bmatrix} = \\boldsymbol{X\\theta}$$\n",
    "\n",
    "where $\\boldsymbol{X\\theta}$ is an $m \\times 1$ vector. \n",
    "\n",
    "See the tutorial, `t1-numpy.ipynb`, for information about `np.dot` specifically, and about matrix multiplication in general.</div>\n",
    "\n",
    "The first step is to compute the difference between each of the $m$ estimates in the vector $\\boldsymbol{X\\theta}$ and the corresponding target values in the vector $y$. The next step is to square this difference, which we may use the built-in NumPy function `np.power(---,---)`.\n",
    "\n",
    "So, the vector of quantities $(h(x^{(i)}; \\boldsymbol{\\theta}) - y^{(i)})^2$ for each _i_ of the _m_ examples can be computed and stored to a local variable `scores` with one line of code of the form\n",
    "\n",
    "~~~python\n",
    "# YOUR CODE HERE\n",
    "scores = np.power(---, ---)\n",
    "return\n",
    "~~~  \n",
    "\n",
    "\n",
    "<u>Second Line of Code</u>\n",
    "\n",
    "What remains is to sum `scores` and divide by the number of training examples multiplied by two. The result should be a scalar saved to the variable `ans`:\n",
    "\n",
    "~~~python\n",
    "# YOUR CODE HERE\n",
    "scores = np.power(---, ---)\n",
    "ans = ---\n",
    "return ans\n",
    "~~~\n",
    "\n",
    "where `ans` will use the value computed in the first line of code and saved to the variable `scores`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "979c88f3536c3cc985b98515affebcec",
     "grade": false,
     "grade_id": "costJ",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def costJ(X, y, theta):\n",
    "    \"\"\"Implement the squared-error cost function, compute_cost_J.\n",
    "    compute_cost_J(X, y, theta) computes the cost of using the\n",
    "    theta to parameterize a linear regression hypothesis to fit\n",
    "    the data in X and y.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    cost = np.dot(X, theta)\n",
    "    scores = np.power((cost - y), 2)\n",
    "    \n",
    "    ans = np.divide(np.sum(scores), 2*m)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bb4f2067146165e30330da64d386fa9",
     "grade": true,
     "grade_id": "costJ-test1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Test cell 1 for costJ\"\"\"\n",
    "assert round(costJ(X,y,theta), 1) == 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ded5137b7a4a0c66af4628d4dce2ec54",
     "grade": true,
     "grade_id": "costJ-test2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test cell 2 for costJ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Test cell 2 for costJ\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96d1ef3e688b46e1e17a6b702f22f3ee",
     "grade": false,
     "grade_id": "cell-4d71ef4a29312e25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Step 3**. We now turn to the implementation of gradient descent. The function,\n",
    "    \n",
    "    batchGradientDescent(X, y, theta, alpha, num_iterations)\n",
    "    \n",
    "takes 5 arguments:\n",
    "\n",
    "    X - an array of features from data\n",
    "    y - an array of labels from data\n",
    "    theta - an array of parameters that gradient descent adjust to minimize loss according to J_cost\n",
    "    alpha - the learning rate\n",
    "    num_iterations - the number of iterations that the algorithm runs before terminating.\n",
    "\n",
    "The loop structure to iterate gradient descent `num_iterations` times is given for you. What is missing are the simultaneous updates of the two components of __$\\theta$__, namely $\\theta_0$ and $\\theta_1$.\n",
    "\n",
    "\n",
    "\n",
    "__Gradient Descent Algorithm__\n",
    "\n",
    "    Enter loop\n",
    "        Repeat:\n",
    "               \n",
    "$$\\theta_0=:\\theta_0 - \\alpha \\frac{\\partial} {\\partial \\theta_0} J(\\theta_0, \\theta_1)$$\n",
    "$$\\theta_1=:\\theta_1 - \\alpha \\frac{\\partial} {\\partial \\theta_1} J(\\theta_0, \\theta_1)$$\n",
    "         \n",
    "        Stop at convergence\n",
    "    Exit loop\n",
    "    \n",
    "\n",
    "What you will need to do complete two steps within the for loop, namely update theta and create a history of the computed cost function _J($\\theta$)_ for each\n",
    "iteration of the algorithm.\n",
    "\n",
    "\n",
    "__1. Update theta__\n",
    "\n",
    "The code initializes `theta_new` as a copy of theta. Within the for loop, your simultaeous update of `theta_new` should be completed in one line of\n",
    "_vectorized code_:\n",
    "\n",
    "```python \n",
    "theta_new -= alpha <operation> --- # complete your line of code  \n",
    "```\n",
    "\n",
    "with `<operation>` from the set {â€”, $*$, /} and `-=` a built-in [assignment operator](https://stackoverflow.com/questions/37845445/and-symbols-in-python/37845498). Note that `X.T` is the transposition of array `X`.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>Hint</b>: The partial derivative terms for each component $\\theta_j$ of the parameter vector $\\boldsymbol{\\theta}$ for is:\n",
    "$$\n",
    "\\theta_j:   {\\frac{\\partial}{\\partial\\theta_j}  J(\\theta_1, \\ldots, \\theta_j \\ldots, \\theta_n)} \\ = \\ \\frac{1}{m} \\sum_{i=1}^m (h(x^{(i)}; \\boldsymbol{\\theta}) - y^{(i)}) \\cdot x_j^{(i)}, $$\n",
    "where $x_0^{(i)} = 1$ for all $i$. \n",
    "    \n",
    "We saw above that $h(x^{(i)}; \\boldsymbol{\\theta}) - y^{(i)})$ is calculated by $X \\theta$. Then, the partial derivatives are either computed by $(X \\theta) X$ or $(X \\theta) X^T$. Which is it? Why? </div>\n",
    "  \n",
    "__2. Store history of the cost function J__\n",
    "\n",
    "The second step is to write into the $j$th element of the vector `J_history` the result from computing the cost determined by executing costJ using `theta_new` that was just updated in the $j$th iternation. Bear in mind that `idx` is used as the index for `num_iterations`, to avoid confusing this for indices used to index rows ($i$) and columns ($j$) of our training set.\n",
    "___\n",
    "\n",
    "Now, complete the implementation of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b6a3e1e23bea1efdf99977d63c16322",
     "grade": false,
     "grade_id": "cell-c89997583053c8e9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def batchGradientDescent(X, y, theta, alpha, num_iterations):\n",
    "    \"\"\"gradient_descent performs batch gradient descent to minimize theta and return a history\n",
    "    of the gradient steps to plot.\n",
    "\n",
    "    gradient_descent updates theta by taking a number of gradient steps, fixed by the\n",
    "    parameter num_iterations, where the size of those steps is determined by the learning\n",
    "\n",
    "    rate, alpha.\n",
    "    \"\"\"\n",
    "    ## Initialize variables\n",
    "    # m is the number of training samples\n",
    "    m= len(y)\n",
    "\n",
    "    # J_history is the cost function history, intialized to a vector of zeros\n",
    "    # for each iteration step\n",
    "    J_history = np.zeros(num_iterations)\n",
    "    # initialize theta_new with a copy of theta.\n",
    "\n",
    "    theta_new = theta.copy()\n",
    "    for idx in range(num_iterations):\n",
    "        # 1st line: update theta_new\n",
    "        # 2nd line: update J_history with compute_cost using theta_new\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        #prediction = np.dot (X, theta_new)\n",
    "        #theta_new -= alpha* ( X.T.dot ( (prediction - y))) * (1/m)\n",
    "        \n",
    "        #grad = np.dot(X.T, (np.dot(X, theta_new)-y))\n",
    "        \n",
    "        theta_new -= alpha* np.dot(X.T, (np.dot(X, theta_new)-y)) * (1/m)\n",
    "        J_history[idx] = costJ(X , y, theta_new)\n",
    "        \n",
    "\n",
    "    return theta_new, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06eebdea8ce9b235aeb972b039841a11",
     "grade": false,
     "grade_id": "cell-d15c4c2300cad48a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## III. Running Gradient Descent\n",
    "\n",
    "The next step is to set the learning rate and number of iterations. Setting the correct values for these two parameters depends on the data set. In practise, you would need to try out different values of these parameters to see how your alhorithm performed. But,I provide you with parameter settings that will work if your code up to now is implemented correctly.  \n",
    "\n",
    "Specifically, be sure the next cell has the following parameter values:\n",
    "\n",
    "~~~python\n",
    "## gradient_descent adjustable parameters\n",
    "# learning rate\n",
    "alpha = 0.2\n",
    "#number of iterations\n",
    "iterations = 1100\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gradient_descent adjustable parameters\n",
    "# learning rate\n",
    "alpha = 0.2\n",
    "#number of iterations\n",
    "iterations = 1100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69accbf7d10fea078af35e666a647dde",
     "grade": false,
     "grade_id": "cell-0b798470b6f642c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell to instantiate `alpha` and `iterations`.\n",
    "Now we are ready to run gradient descent with the parameter settings for `alpha` and the number of `iterations` excuting the following line of code in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gradient descent\n",
    "theta_new, J_history = batchGradientDescent(X, y, theta, alpha, iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acf0a060e6117dceb606b182635400a4",
     "grade": false,
     "grade_id": "cell-0f71100dcf57f657",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Gradient descent (correctly parameterized by `alpha` and `iterations`) returns values for $\\theta_0$ and $\\theta_1$ stored in `theta_new`,along with `J_history`.\n",
    "\n",
    "Run the next cell to see the values for $\\theta_0$ and $\\theta_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.22558776, 2.164952  ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the output of batchGradientDescent\n",
    "theta_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1310f648faa9e9ce20382386b0a39a65",
     "grade": false,
     "grade_id": "cell-ef954a0cd14dbbf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "When implemented correctly, running `batchGradientDescent` on `data` with learning rate `alpha = 0.2` and `iterations = 1100` should return a value for $\\theta_0$ that is aproximately $3.2$ and a value for $\\theta_1$ that is aproximately $2.2$, and `J_history` should be an array of monotonically decreasing values.\n",
    "\n",
    "\n",
    "The following cells are hidden test cells that are used for grading. We will not label test cells hereafter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61473303f152655e913b61fadc529942",
     "grade": true,
     "grade_id": "BGD-test1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e0a6c9ff6e6ec03129b10387e26a9fc",
     "grade": true,
     "grade_id": "BDG-test2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c831b38a4f503a39d50c1046c88a84c7",
     "grade": true,
     "grade_id": "BGD-test3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56d814bda211653ed00210c816123015",
     "grade": false,
     "grade_id": "cell-9171f4c3368f3043",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## IV. Visualization, Tuning, and Debugging\n",
    "\n",
    "### Plotting the history of J\n",
    "\n",
    "The variable J_history stores the computed cost function for each iteration of batchGradientDescent , which for our example we set to 1100 iterations. How do we determine that number of iterations is long enough to converge? One way to do this is to plot the value of $J(\\theta)$ at each iteration to see its\n",
    "performance.\n",
    "\n",
    "The next cell plots `J_history` with your initial parameters.  If your implementation is correct, your cost function should decrease with each iteration and <i>loosely</i> resemble the following plot, which is taken from a different problem:   \n",
    "\n",
    "<img src=\"ps1_fig0.png\" alt=\"sample learning rate\" width=\"400\"/>\n",
    "\n",
    "<div class=\"alert alert-info\"><b>Hint:</b> You can use this plot to check whether you have implemented `batchGradientDescent` correctly, and perhaps to give you clues about how to correct\n",
    "your code if you find something amiss.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$J(\\\\theta)$')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUi0lEQVR4nO3df7Dld13f8efr3t1NNj+QQG4wktSNBq0ZK7+2DOHXhIAKaKFObUWaClPrVooWa2cYUp3p2JnOYKloW0jHHUBpJWEcAcVUIQGJmSCE3I2bX4YfgSQaCe6FGMjv7I93//h+7+6559xk797d8+N+7vMxc+ae8z3nfD+fz27yup99n8/5fFNVSJLaNzftDkiSJsPAl6RNwsCXpE3CwJekTcLAl6RNYsu0O/BkzjzzzNqxY8e0uyFJG8aePXu+UVULqz0304G/Y8cOFhcXp90NSdowktz9RM9Z0pGkTcLAl6RNwsCXpE3CwJekTcLAl6RNwsCXpE3CwJekTaLJwP9fn/oyf/6lpWl3Q5JmSpOBf9k1X+Ezd3xj2t2QpJnSZOADeGEXSVqpycBPpt0DSZo9TQY+gBN8SVqpycAPYN5L0kptBr41HUka0WTggyUdSRrWZOA7v5ekUU0GPkBZxZekFdoMfKf4kjRiopc4THIX8ABwEDhQVTvH1ZY1fElaaRrXtH15VY113wMn+JI0qs2SjiRpxKQDv4CrkuxJsmu1FyTZlWQxyeLS0vp2vHQdviSNmnTgv7iqnge8GnhLkpcNv6CqdlfVzqraubCwsO6G3DxNklaaaOBX1df6n/uAjwIvGEc7iVsrSNKwiQV+klOTnL58H/gR4NaxtDWOk0rSBjfJVTrPAD7a19e3AJdX1cfH1ZgVHUlaaWKBX1VfBZ49ibb80FaSRjW7LNOtFSRppSYD3/m9JI1qMvDBGr4kDWsy8C3hS9KoJgMfXIcvScMaDXyn+JI0rNHAt4YvScOaDPyuhm/iS9KgNgN/2h2QpBnUZOCDJR1JGtZk4LssU5JGNRn44AxfkoY1Gfixii9JI5oMfHDzNEka1mTgW8OXpFFNBj5Yw5ekYU0GvhN8SRrVZOCD37OVpGFNBn4SSzqSNKTJwJckjWo28F2WKUkrNRn4LsuUpFFNBj7gp7aSNKTJwHeGL0mjmgx8cIIvScOaDHw3T5OkUU0GPkC5EF+SVmgy8K3hS9KoJgMfrOFL0rCJB36S+SR/meTKsbWBu2VK0rBpzPDfCtw+zgZiTUeSRkw08JOcA/wY8N5xt+UEX5JWmvQM/7eAtwGHxtmI83tJGjWxwE/y48C+qtpzlNftSrKYZHFpaWnd7bksU5JWmuQM/8XAa5PcBXwIuDjJ7w2/qKp2V9XOqtq5sLCwvpac4kvSiIkFflVdWlXnVNUO4PXAn1XVJWNrb1wnlqQNqsl1+E7wJWnUlmk0WlXXANeMt5Gxnl2SNpw2Z/iJV7ySpCFtBv60OyBJM6jJwAe3VpCkYU0GvjsrSNKoJgMfnOFL0rAmA98rXknSqCYDH3CVjiQNaTLwreFL0qgmAx+s4UvSsGYDX5K0UrOB7wRfklZqMvCTWNKRpCFtBv60OyBJM6jJwO84xZekQU0GvssyJWlUk4EPLsuUpGFNBr4zfEka1WTggxV8SRrWZOC7eZokjWoy8AHKIr4krdBk4FvDl6RRTQY+WMOXpGFNBn5wWaYkDWsy8K3pSNKoNgMfSzqSNKzJwHd+L0mjmgx8cFmmJA1rMvAt4UvSqCYDX5I0qsnAd4IvSaMmFvhJTk7y+SQ3Jbktya+Nsz1L+JK00pYJtvUYcHFVPZhkK3Bdkj+tqs+d6IZiEV+SRkws8KtbNvNg/3BrfxvbPLxciS9JK0y0hp9kPsleYB9wdVVdv8prdiVZTLK4tLS0vnawpCNJwyYa+FV1sKqeA5wDvCDJD67ymt1VtbOqdi4sLKyrHSs6kjTqmAM/yalJ5o+n0aq6H7gGeNXxnOfJ2xjXmSVpYzpq4CeZS/KGJP8vyT7gC8C9/UqbdyZ51loaSrKQ5Kn9/e3AK/tznXBe8UqSRq1lhv9p4HuBS4HvrKpzq+os4KXA54B3JLlkDec5G/h0kpuBG+hq+Feus99H5Ye2krTSWlbpvLKq9g8frKr7gA8DH+6XWT6pqroZeO6xd3EdnOBL0oi1BP4zk/w74HzgPmAv8MdVdffyC1b7hTBt1vAlaaW1lHT+CPgi8B7gh4FnA9cmeU+Sk8bZufVygi9Jo9YS+PNV9b6q+hRwX1X9HF1N/y5g9zg7dzyc4EvSSmsJ/E8m+YX+fgFU1YGqeidw4dh6dhxchy9Jo9ZSw/9l4NIki8B3JdkFPEwX9t8cZ+eOi1N8SVrhqDP8qjpUVf8VeBmwC/hO4PnArcCrx9u99QlxWaYkDTnqDD9JqvMw8LH+tuprxtHB9bCkI0mj1vTFqyS/mOQfDB5Msi3JxUk+ALxxPN1bv9n59SNJs2EtNfxXAf8auCLJecD9wHa6XxZXAb9ZVXvH1cH1cIYvSaOOGvhV9ShwGXBZ/43aM4FH+g3QZpYTfElaaS01/HcBN/e326rq3rH36ji5eZokjVpLSecO4IXAzwE/kOTrHPkFcANwbVU9Nr4urs8MfYYsSTNhLSWdywYf93X8fwT8EPBm4LeTvLmqPjGeLh47a/iSNOqYr2lbVXcCd9Ivz0xyNnAlMDOBD9bwJWnYcV/isK/pX34C+iJJGqMTck3bqvqNE3GeE8kSviStNNGLmE9KEks6kjSkzcCfdgckaQY1GfiANR1JGtJk4LssU5JGNRn44LJMSRrWZOA7wZekUU0GPljCl6RhTQZ+LOJL0ogmAx/wEoeSNKTJwA+WdCRpWJuBb0VHkkY0GfjgDF+ShjUa+E7xJWlYo4HvF68kadjEAj/JuUk+neT2JLcleev42hrXmSVp4zrmK14dhwPAf6yqG5OcDuxJcnVV/dU4GvOatpK00sRm+FV1b1Xd2N9/ALgdeOY42nKCL0mjplLDT7IDeC5w/SrP7UqymGRxaWlpned3lY4kDZt44Cc5Dfgw8EtV9e3h56tqd1XtrKqdCwsL62uD+E1bSRoy0cBPspUu7D9YVR8ZVztzc87wJWnYJFfpBHgfcHtVvWusbREOmfiStMIkZ/gvBv4VcHGSvf3tNeNoKHEdviQNm9iyzKq6jgktoJlLLOlI0pAmv2mbYElHkoY0GfjO8CVpVJOBH5zhS9KwNgPfGb4kjWgy8OfiXjqSNKzJwO8+tJ12LyRptjQZ+HNxawVJGtZk4DvDl6RRjQa+H9pK0rAmA98PbSVpVJOB7+ZpkjSqycCfc/M0SRrRZOAn4ZCf2krSCo0GvjN8SRrWZOC7eZokjWoy8N08TZJGNRn4c3PO8CVpWJOB7wxfkka1GfiJH9pK0pAmA99v2krSqCYD383TJGlUk4HfLcs08SVpUJOB331oO+1eSNJsaTPwE8A6viQNajLw5w4H/pQ7IkkzpMnA7/PetfiSNKDJwJ/rA9+4l6Qjmgz85Rq+M3xJOqLRwO9+mveSdMTEAj/J+5PsS3LruNvyQ1tJGjXJGf7vAq+aREP9BN+SjiQNmFjgV9W1wH2TaOvwDH8SjUnSBtF0Dd8ZviQdMXOBn2RXksUki0tLS+s9BwB16ET2TJI2tpkL/KraXVU7q2rnwsLCus5xZB2+M3xJWjZzgX8iHPnQdqrdkKSZMsllmVcAnwW+P8k9SX52XG3Nzbl5miQN2zKphqrqpyfV1pFv2k6qRUmafU2XdJzhS9IRTQb+lr6kc8ApviQd1mbgz3fDOnDQwJekZU0G/tb55Rm+C/ElaVmTgT9vSUeSRjQZ+FvmumHtP+gMX5KWNRn4yyWdg87wJemwJgN/uaSz3w9tJemwJgN/6+FVOpZ0JGlZk4G/vA7fko4kHdFm4Pc1/P0GviQd1mbgz1nSkaRhTQa+6/AlaVSTgb/VrRUkaUSTgb/FrRUkaUSbge86fEka0WTgb982D8Aj+w9OuSeSNDuaDPzTTuou5PXQYwem3BNJmh1NBv72rfPMBR581MCXpGVNBn4STj1pCw86w5ekw5oMfIDTDXxJWqHZwH/6aSex74HHpt0NSZoZzQb+eWeeyh1/9wBVLs2UJIAt0+7AuLzoe5/Ox276Gv/k3ddx/sJpnHHqNs44ZRtnnLKVp56yjads38rJW+bYvm2e7VvnOfnwbY6t83NsmQvzcyHJtIciSSdEs4H/z3eeyzcfepxrv7TE4t1/z/0P719XTX8u3d4883Nhy9wcc4Et83PMJczPQQjLvxOWfzUM/pI4/Nzh1+Tw4+HXZ+Akq51L0ubwtFO28fs/f+EJP2+zgT8/F97y8vN5y8vPP3zs8QOHuP+Rx/nWw/v59qP7eXT/IR7df5BH9h/kkccPHr5/4FBx8GBx4FBxqLqfB4duBw4Vhw4VRVcyWq4cLReQqjj8HCPP1YrXLT+3XH46XISyGiVtSqefPJ5objbwV7NtyxxnnX4yZ51+8rS7IkkT1+yHtpKklQx8SdokDHxJ2iQmGvhJXpXki0nuSPL2SbYtSZvdxAI/yTzwHuDVwAXATye5YFLtS9JmN8kZ/guAO6rqq1X1OPAh4HUTbF+SNrVJBv4zgb8ZeHxPf2yFJLuSLCZZXFpamljnJKl1kwz81b4yOvLVoqraXVU7q2rnwsLCBLolSZvDJL94dQ9w7sDjc4CvPdkb9uzZ840kd6+zvTOBb6zzvbOu5bFB2+NzbBvXRhnfdz/RE5nUbpJJtgBfAl4B/C1wA/CGqrptTO0tVtXOcZx72loeG7Q9Pse2cbUwvonN8KvqQJJfAD4BzAPvH1fYS5JGTXQvnar6E+BPJtmmJKnT8jdtd0+7A2PU8tig7fE5to1rw49vYjV8SdJ0tTzDlyQNMPAlaZNoLvA3+gZtSc5N8ukktye5Lclb++NPS3J1ki/3P88YeM+l/Xi/mORHp9f7tUkyn+Qvk1zZP25pbE9N8gdJvtD/HV7YyviS/If+v8lbk1yR5OSNPLYk70+yL8mtA8eOeTxJnp/klv65/5lZvi5pVTVzo1vu+RXge4BtwE3ABdPu1zGO4Wzgef390+m+u3AB8N+At/fH3w78en//gn6cJwHn9eOfn/Y4jjLGXwYuB67sH7c0tg8A/6a/vw14agvjo9sG5U5ge//494E3beSxAS8DngfcOnDsmMcDfB64kG43gT8FXj3tsT3RrbUZ/obfoK2q7q2qG/v7DwC30/3P9jq6MKH/+U/7+68DPlRVj1XVncAddH8OMynJOcCPAe8dONzK2J5CFyLvA6iqx6vqfhoZH90y7u39lyhPofum/IYdW1VdC9w3dPiYxpPkbOApVfXZ6tL//wy8Z+a0Fvhr2qBto0iyA3gucD3wjKq6F7pfCsBZ/cs22ph/C3gbcGjgWCtj+x5gCfidvmT13iSn0sD4qupvgf8O/DVwL/CtqrqKBsY25FjH88z+/vDxmdRa4K9pg7aNIMlpwIeBX6qqbz/ZS1c5NpNjTvLjwL6q2rPWt6xybCbH1ttCVyL431X1XOAhurLAE9kw4+tr2a+jK2d8F3Bqkkue7C2rHJvJsa3RE41nQ42ztcA/5g3aZlGSrXRh/8Gq+kh/+O/6fz7S/9zXH99IY34x8Nokd9GV2y5O8nu0MTbo+ntPVV3fP/4Dul8ALYzvlcCdVbVUVfuBjwAvoo2xDTrW8dzT3x8+PpNaC/wbgGclOS/JNuD1wMem3Kdj0n/C/z7g9qp618BTHwPe2N9/I/BHA8dfn+SkJOcBz6L7EGnmVNWlVXVOVe2g+7v5s6q6hAbGBlBVXwf+Jsn394deAfwVbYzvr4EXJjml/2/0FXSfL7UwtkHHNJ6+7PNAkhf2fy4/M/Ce2TPtT41P9A14Dd3Klq8AvzLt/qyj/y+h+yfhzcDe/vYa4OnAp4Av9z+fNvCeX+nH+0VmeIXA0Dgv4sgqnWbGBjwHWOz//v4QOKOV8QG/BnwBuBX4v3QrVjbs2IAr6D6P2E83U//Z9YwH2Nn/mXwFeDf9DgazeHNrBUnaJFor6UiSnoCBL0mbhIEvSZuEgS9Jm4SBL0mbhIGvmZPkwf7njiRvOMHn/k9Dj//iRJ7/REvypiTvnnY/1AYDX7NsB3BMgZ9k/igvWRH4VfWiY+zThrKGPw9tIga+Ztk7gJcm2dvvxT6f5J1Jbkhyc5J/C5DkonTXELgcuKU/9odJ9vT7t+/qj72DbrfHvUk+2B9b/tdE+nPf2u9t/lMD574mR/a4/+Bq+533r/n1JJ9P8qUkL+2Pr5ihJ7kyyUXLbffv2ZPkk0le0J/nq0leO3D6c5N8vN+H/T8PnOuSvr29SX57Odz78/6XJNfTbdsrdab9zS9v3oZvwIP9z4vov43bP94F/Gp//yS6b7Se17/uIeC8gdc+rf+5ne5bkE8fPPcqbf0z4Gq6ayo8g24rgbP7c3+Lbo+UOeCzwEtW6fM1wG/0918DfLK//ybg3QOvuxK4qL9f9N/YBD4KXAVsBZ4N7B14/7103wBdHstO4AeAPwa29q+7DPiZgfP+i2n/PXqbvduWY/4NIU3PjwA/lOQn+8ffQbenyeN0+5rcOfDaf5/kJ/r75/av++aTnPslwBVVdZBuA60/B/4x8O3+3PcAJNlLV2q6bpVzLG90t6d/zdE8Dny8v38L8FhV7U9yy9D7r66qb/btf6Tv6wHg+cAN/T84tnNko6+DdJvvSSsY+NpIAvxiVX1ixcGuRPLQ0ONXAhdW1cNJrgFOXsO5n8hjA/cP8sT/3zy2ymsOsLJ0OtiP/VW1vLfJoeX3V9Wh/iIjy4b3P1nelvcDVXXpKv14tP/FJa1gDV+z7AG6yzwu+wTw5n77aJJ8X3+BkWHfAfx9H/b/EHjhwHP7l98/5Frgp/rPCRborlx1InZ3vAt4TpK5JOeyvqs+/XC6a61up7ua0mfoNvb6ySRnweFrsX73CeivGuYMX7PsZuBAkpuA3wX+B12p48b+g9MlVr+c3MeBn09yM93Ohp8beG43cHOSG6vqXw4c/yjdB5w30c2g31ZVX+9/YRyPz9BdC/YWuvr7jes4x3V0u1OeD1xeVYsASX4VuCrJHN2Oj28B7j7O/qph7pYpSZuEJR1J2iQMfEnaJAx8SdokDHxJ2iQMfEnaJAx8SdokDHxJ2iT+P8bE7UhmBFCLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot cost function vs. iteration\n",
    "plt.plot(J_history)\n",
    "plt.xlabel(r'Iteration number' )\n",
    "plt.ylabel(r'$J(\\theta)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d6c5744cd43cacb6b8c25574b26bf30",
     "grade": false,
     "grade_id": "cell-5fa3a70db0fd500e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Selecting Learning Rates\n",
    "\n",
    "We selected the learning rate `alpha = 0.2` and `num_iterations = 1100`. The previous plot can tell you whether your model is converging.  Suppose it does. What further can you do to improve your model?  You can adjust either the learning rate `alpha` or the number of iterations `iters`. \n",
    "\n",
    "Let's look at the case where `iters = 20` and ask whether any different learning rates would be better in terms of minimizing $J(\\theta)$ within the first 20 iterations. To look at several learning rates at once, we can define a list\n",
    "\n",
    "~~~python\n",
    "alphas = [ ---, ---, ---, ---, ---]\n",
    "iters = 20\n",
    "~~~\n",
    "\n",
    "to compute and plot different learning rates at once.\n",
    "\n",
    "In the next cell, supply a range of learning rates to `alpha` to plot and compare with respect to a fixed number of iterations. \n",
    "\n",
    "<div class=\"alert alert-info\"><b>Tip:</b> You may write a piece of code to find a good vector `alpha` of learning rates to plot.  However, keep in mind that the second validation check for your notebook limits that your submission is within an upper bound on computational resources available to grade it.  This computational bound will very likely not affect you in this first assignment, but this ceiling is likely to become a constraint for you to manage in future assignments. </div>\n",
    "\n",
    "Note that this plot and the question below only looks at the first 20 iterations.\n",
    "\n",
    "Run the next cell, then answer the Question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff0a96c0e50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Finding minimum alpha ------\n",
    "# a = list(np.linspace(0.20, 0.99, 80))\n",
    "# iters = 20\n",
    "# temp = []\n",
    "# for aa in a:\n",
    "#     theta_new, J_history = batchGradientDescent(X, y, theta, aa, iters)\n",
    "#     plt.plot(J_history, label='learning rate={0}'.format(aa) )\n",
    "#     temp.append(J_history[19])\n",
    "    \n",
    "# min_value = min(temp) #find mimimum J\n",
    "\n",
    "# min_index = temp.index(min_value) #find minimum index\n",
    "# print(a[min_index]) #print value of alpha for min value\n",
    "# #0.8400000000000001 -------\n",
    "\n",
    "alphas = [0.78, 0.80, 0.82, 0.84, 0.86]\n",
    "iters = 20\n",
    "for aa in alphas:\n",
    "    theta_new, J_history = batchGradientDescent(X, y, theta, aa, iters)\n",
    "    plt.plot(J_history, label='learning rate={0}'.format(aa) )\n",
    "\n",
    "plt.ylabel(r'$J(\\theta)$')\n",
    "plt.xlabel(r'Number of Iterations' )\n",
    "plt.legend(loc='best', frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8f93c2f45cf4edd715b13b92b2d38d4",
     "grade": false,
     "grade_id": "cell-fb0a79d046b5e584",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Question 2\n",
    "\n",
    "What is the learning rate `alpha` that yields the lowest score $J(\\theta)$ after exactly 20 iterations? Limit your search to values of `alpha` to two decimal places.  For example, if `alpha = 0.07` is your answer, you would finish function `ans_two()` by writing\n",
    "\n",
    "~~~python\n",
    " num = 0.07\n",
    "\n",
    "~~~\n",
    "\n",
    "The grader expects your `ans_two()` to return a float `num` of no more than two decimal places. Enter your answer below.\n",
    "\n",
    "---\n",
    "### Q2 Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d865e09b6a872968f3f034f56000f414",
     "grade": false,
     "grade_id": "ans_two",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ans_two():\n",
    "    \"\"\" Returns a float.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :num:  float\n",
    "        A scalar representing your choice of alpha.\n",
    "    Returns\n",
    "    -------\n",
    "    :num:\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    num = 0.84\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c589d42329ef84c71c2b99d3a33a43c1",
     "grade": true,
     "grade_id": "cell-74cfd101ab4b180f",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "num = ans_two()\n",
    "if type(num) == float and str(num)[::-1].find('.') <= 2:\n",
    "    assert True\n",
    "else:\n",
    "    raise AssertionError(\"Check that your answer is a float of no more than two decimal places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fbaeb370ac17f8c4cf2983556bc8742",
     "grade": true,
     "grade_id": "cell-b8fa64c75b3c251c",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c72f9615c18a103c40c50078ad24ecaf",
     "grade": true,
     "grade_id": "ans_two-test1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "614043a04cd333089039c405e484ec8d",
     "grade": false,
     "grade_id": "cell-a110ae97236a41a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Question 3\n",
    "\n",
    "Which are true? Mark all and only that apply.\n",
    "\n",
    "Suppose that $J(\\boldsymbol{\\theta})$ is a continuously differentiable and convex function and $\\theta$ is in $\\mathbb{R}^2$.\n",
    "\n",
    "  * A) Gradient Descent is guaranteed to converge to a local minima of <em>J</em> for all learning rates <em>Î±</em>.\n",
    "  * B) Gradient Descent is guaranteed to converge to a local minima of <em>J</em> for some learning rates <em>Î±</em>\n",
    "  * C) There is no learning rate <em>Î±</em> such that Gradient Descent is guaranteed to converge to a local minima of <em>J</em>.\n",
    "  *  D) The gradient of <em>J</em> is zero at the minimum.\n",
    "  * E) The gradient of <em>J</em> points in the direction in $\\mathbb{R}^2$ of the steepest increase in the value of <em>J</em>.\n",
    "  * F) None of the above are true.\n",
    "---\n",
    "\n",
    "### Q3 Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b75a2021f0ad40a209b44d4767295039",
     "grade": false,
     "grade_id": "ans_three",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ans_three():\n",
    "    \"\"\" Returns a list of your answers.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :ans:  list\n",
    "        The list of your answers. Elements of :ans: are strings.\n",
    "    Returns\n",
    "    -------\n",
    "    :ans: ['B', 'D', 'E']\n",
    "    \"\"\"\n",
    " \n",
    "    # YOUR CODE HERE\n",
    "    ans = ['B', 'D', 'E']\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ae75885ecc406c4c4729fb7537355f3",
     "grade": true,
     "grade_id": "ans_three-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test cell for ans_three()\n",
    "ans = ans_three()\n",
    "%run -i 'ans_format_test.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c20419ba66f6829b1222d9322f9c2e3",
     "grade": false,
     "grade_id": "cell-1f23e9f991d222b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Question 4\n",
    "\n",
    "Instead of Gradient Descent, which we are using to compute an approximate solution to OLS regression, we can instead use the Normal Equation to calculate an analytical solution. \n",
    "\n",
    "Which of the following is true about the Normal Equation? Mark all and only that apply.\n",
    "\n",
    "  * A) The number of features must be less than the number of training examples.\n",
    "  * B) There is no learning rate hyperparameter to choose.\n",
    "  * C) There is no need to iterate.\n",
    "  * D) The speed of computing the normal equation slows linearly as the number of features increases.\n",
    "  * E) The speed of computing the normal equation slows linearly as the number of training examples increases.\n",
    "  * F) None of the above are true.\n",
    "\n",
    "---\n",
    "### Q4 Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9937c9179e5cee78d01dce19a64f05f",
     "grade": false,
     "grade_id": "ans_four",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ans_four():\n",
    "    \"\"\" Returns a list of your answers.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :ans:  list\n",
    "        The list of your answers. Elements of :ans: are strings.\n",
    "    Returns\n",
    "    -------\n",
    "    :ans: ['B','C','E']\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    ans = ['B', 'C', 'E'] #!!!!! A : not necessarily for moore penrose pseudo inverse\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1e4af7d1b99178bec62941a1fff881c",
     "grade": true,
     "grade_id": "ans_four-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans = ans_four()\n",
    "%run -i 'ans_format_test.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea8e4b9c27d39547c3cedef352ac5265",
     "grade": false,
     "grade_id": "cell-0804cea1022eff24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# PART B - Scikit-learn Linear Regression\n",
    "\n",
    "Naturally, there are built-in libraries for regression models.  In fact, it just takes a few lines of code once we import `LinearRegression` from the `linear_model` methods in the `sklearn` (scikit-learn) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37ff5bdf8e64ee3738bd3e1cdbd914b7",
     "grade": false,
     "grade_id": "cell-efc7c77c6494db74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# import sklearn linear regression \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3aace885f52b222e040d821e4f47138",
     "grade": false,
     "grade_id": "cell-2936014478ce7c0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Scikit-learn uses a common [API](https://en.wikipedia.org/wiki/Application_programming_interface) for building models. So, the sequence we follow to build a simple linear model resembles the sequence of steps for building a wide range of models.  This is a good opportunity, therefore, to become aquainted with the scikit-learn workflow.\n",
    "\n",
    "Basically, there are two steps:\n",
    "\n",
    " - Instantiate a model\n",
    "  \n",
    " - Fit the model\n",
    "\n",
    "Followed by plotting and some rudimentary analysis of the model. Later in the course we will add a third step, which involves making predictions and evaluating the accuracy of those predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = LinearRegression()\n",
    "# fit the model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcf12682a14d1ce50cbeb128201723ce",
     "grade": false,
     "grade_id": "cell-018717d26ed6eb9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And that's it! \n",
    "\n",
    "How does this method relate to what you did in PART A?  To retrieve the parameters, we apply the following methods to `model`:\n",
    "\n",
    " - `.intercept_`\n",
    " - `.coef_`\n",
    " \n",
    "Note that the trailing underscore `_` is simply used to avoid naming conflicts in sklearn. You can interpret each as giving you the intercept ($\\theta_0$) and the remaining coefficients ($\\theta_1, \\theta_2, \\ldots$) in your model, respectively. Here (hopefully!) some of what you learned in PART A can be useful to understand what the next lines of code are doing. \n",
    "\n",
    "Specifically, since sklearn linear regression can model multiple regression problems (i.e., problems with 2 or more features), the method `.coef_` returns an np.array rather than single number.  Hence, to retrieve the parameter value for $\\theta_1$, we index by `[1]` into this array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_0: 3.2255877706752263\n",
      "theta_1: 2.1649519939763175\n"
     ]
    }
   ],
   "source": [
    "#print theta0 and theta1\n",
    "print('theta_0:', model.intercept_)\n",
    "print('theta_1:', model.coef_[1])  # model.coef_ returns an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f6afe111fe1cc6fb453764d0bd6a187",
     "grade": false,
     "grade_id": "cell-3344f2765f1b6622",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Compare the values you computed here to those you computed above.  \n",
    "\n",
    "Next, we produce a plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff0c8fdf910>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.title('2017 World Happiness by Country')\n",
    "plt.xlabel(r'Per Capita GPD')\n",
    "plt.ylabel(r'Happiness Score')\n",
    "plt.plot(x, model.predict(X),color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab1274377fa2950bb28036399b2c0460",
     "grade": false,
     "grade_id": "cell-8b0a718a767976dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\"><b>Machine Learning and Statistics:</b> You might be surprised to find that scikit-learn's regression library does not include a summary report of the kind you find in <b>R</b> or other statistical software. A common reason given is that scikit-learn is designed for predictive modeling, so the relevant evaluation criteria -- which we will cover later in the course -- are those to do with predictive accuracy.\n",
    "\n",
    "This is unfortunate, since outside of classroom exercises and kaggle competitions, rarely can you get very far solving a real-world problem without understanding your data through statistical analysis.  It is also silly, as predictive modeling is a branch of statistics, after all. \n",
    "\n",
    "    \n",
    "Nevertheless, there is an important point behind this. Machine learning has genuinely advanced our capabilities to do predictive modeling by focusing on \"algorithmic\" approaches that precisely forgo much of what is necessary for traditional, statistical \"data modeling\" approaches to get started. The design and philosophy of `sklearn` is a reflection of this philosophy in machine learning that has taken root over the last couple of decades.\n",
    "\n",
    "</div>\n",
    "\n",
    "One can of course use the [statsmodels](https://www.statsmodels.org/stable/index.html) package to fit a traditional OLS regression and extract summary statistics.  We demonstrate how to do this, next. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   280.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 08 Feb 2022</td> <th>  Prob (F-statistic):</th> <td>2.33e-36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:22:07</td>     <th>  Log-Likelihood:    </th> <td> -154.10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   154</td>      <th>  AIC:               </th> <td>   312.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   152</td>      <th>  BIC:               </th> <td>   318.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.2256</td> <td>    0.139</td> <td>   23.250</td> <td> 0.000</td> <td>    2.951</td> <td>    3.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.1650</td> <td>    0.129</td> <td>   16.757</td> <td> 0.000</td> <td>    1.910</td> <td>    2.420</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.331</td> <th>  Durbin-Watson:     </th> <td>   1.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.847</td> <th>  Jarque-Bera (JB):  </th> <td>   0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.077</td> <th>  Prob(JB):          </th> <td>   0.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.773</td> <th>  Cond. No.          </th> <td>    5.01</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.649\n",
       "Model:                            OLS   Adj. R-squared:                  0.646\n",
       "Method:                 Least Squares   F-statistic:                     280.8\n",
       "Date:                Tue, 08 Feb 2022   Prob (F-statistic):           2.33e-36\n",
       "Time:                        16:22:07   Log-Likelihood:                -154.10\n",
       "No. Observations:                 154   AIC:                             312.2\n",
       "Df Residuals:                     152   BIC:                             318.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.2256      0.139     23.250      0.000       2.951       3.500\n",
       "x1             2.1650      0.129     16.757      0.000       1.910       2.420\n",
       "==============================================================================\n",
       "Omnibus:                        0.331   Durbin-Watson:                   1.194\n",
       "Prob(Omnibus):                  0.847   Jarque-Bera (JB):                0.483\n",
       "Skew:                           0.077   Prob(JB):                        0.785\n",
       "Kurtosis:                       2.773   Cond. No.                         5.01\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.api import OLS\n",
    "OLS(y,X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> <b>OLS vs sklearn regression</b> \n",
    "    \n",
    "OLS regression gives you a classical and, as such, is not designed for large models. Scikit-learn regression, on the other hand, is designed for large models.  This can result in cases where the two give slightly different results.\n",
    "    \n",
    "Both operate within the framework of classical, frequentist statistics.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "098d3d23c25c130bbd5bde4fbc368b40",
     "grade": false,
     "grade_id": "cell-fb354467376434b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Lastly, the [seaborn](https://seaborn.pydata.org/) statistical visualization library is an extension of matplotlib that includes several built-in features that allow you to create appealing and informative graphics.  For instance, we might like to visualize the <b>confidence interval</b> around our model.  The next two lines of code produce a (default) 95% confidence interval, that is, that interval $[L, U]$ is calculated by\n",
    "\n",
    "$$L = \\theta_1 - 1.96(SE\\,\\theta_1) \\qquad U = \\theta_1 - 1.96(SE\\,\\theta_1) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "sns.regplot(x=x,y=y,line_kws = {\"color\": 'r'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a12cf40a970e346bf4e5f0f692bd7a95",
     "grade": false,
     "grade_id": "cell-e85f30c72c0a163e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# PART C - Your Turn\n",
    "\n",
    "Let's review. In Part A you focused on the mechanics of <b>gradient descent</b>, how the mathematical components of <b>ordinary least squares regression</b> (OLS) regression can be represented and computed by NumPy element-wise array operations, and how those computational components fit together into an implementation of Batch Gradient Descent.  You then ran your implementation of gradient descent to find approximate solutions for the vector of coefficients, $\\boldsymbol{\\theta}$, and recorded a step-wise history of values of the cost function, showing the progress of the algorithm in finding values of $\\boldsymbol{\\theta}$ that minimize the cost function $J(\\boldsymbol{\\theta})$.  In Part B you used the SciKit-Learn library to confirm the parameter values and were introduced to the \"logic\" of the sklearn API (which you will see more of, later in the course).  You were also introduced to the statsmodels library, which allows you to produce a traditional OLS regression, among many other things. We used this to produce an OLS model and summary table.  Finally, you were given a brief introduction to the statistical plotting library <b>seaborn</b>, which is an extension of matplotlib.\n",
    "\n",
    "In this section, you will do some of the data preparation work that was done for you to fit a regression model on <b>life expectancy</b>.  The data set `ps1_data2.csv` contains the two columns of data in `ps1_data1.csv` plus a third  column recording the average life expectancy, in years, of each country.\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>Note</b>:\n",
    "The average life expectancy data is scaled to values between 0 and 1. For example, a country whose average lifespan is 79.26 years will appear as 0.7926.\n",
    "</div>\n",
    "\n",
    "Your first task is to run the next cell to load `ps1_data2.csv`.  Then, on your own, you will need to prepare the data set to perform a <b>univariate linear regression model</b> to the explain the target variable <i>happiness</i> from the feature </i> average lifespan.  That is, $x$ will be the life expectancy feature, and $y$ will be the happiness score (as before). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.loadtxt('ps1_data2.csv', delimiter=',')\n",
    "data2 = data2[:,1:] #deleting column 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "466559189b4f26146c691fe6eb5543e2",
     "grade": false,
     "grade_id": "cell-6451b55b3cb7a74c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once `data2` is in the right format to use the code you have written in Part A and the libraries introduced to you in Part B, use those tools (and those tools only) to answer each part of Question 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e54cb6914a394acec40c9e69e085117",
     "grade": false,
     "grade_id": "cell-310dd6116d27cb85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Question 5\n",
    "\n",
    "Run Gradient descent and sklearn linear regression on `data2`.  Be sure to pick new variables names to ensure that all variables correspond to data set `ps_data2` and not to `ps_data1`. \n",
    "\n",
    "There are four quantities that you will need to report about your univariate regression model for the target variable <i>happiness score</i> and independent variable <i>average life expectancy</i>, which we will refer to as \"<b>model 2</b>\": \n",
    "\n",
    " - a) The value of the intercept parameter $\\theta_0$ of a fitted model 2.\n",
    " - b) The value of the coefficient parameter $\\theta_1$ of a fitted model 2.\n",
    " - c) The value of the cost function, $J([\\theta_0, \\theta_1])$, on the fitted parameters for model 2. Note that this is the last value stored in the J_history cost function.\n",
    " - d) The Akaike information criterion score for model 2.\n",
    "\n",
    "The test condition for a, b, c, rounds the correct answers to some $n$ places unknown to you but less than 5 decimal places. Therefore, you should compute each of these values.  Answer d will be evaluated to a precision of one-decimal place.\n",
    "\n",
    "In the following cell, enter the values for for those variables.  Here is the key:\n",
    "\n",
    "~~~python\n",
    "def ans_5():\n",
    "    a =     # a: theta_0 from your fitted model \n",
    "    b =     # b: theta_1 from your fitted model  \n",
    "    c =     # c: the last value of the array J_history \n",
    "    d =     # d: Akaike information criterion score, to 1 decimal place of precision.\n",
    "~~~\n",
    "\n",
    "<div class=\"alert alert-info\"> <b>Hint</b>:\n",
    "If you use different tools from Part A and Part B, it is important that they return the same answers (up to five decimal places of precision) to those parts of Question 5 that they both can answer. Now the hint: You may want to aim for slightly higher precision for some quantities to ensure the test conditions for all four quantities are satisfied. \n",
    "</div>\n",
    "\n",
    "---\n",
    "### Q5 Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41fb86fdcc3f43f9117d125e9faa4952",
     "grade": false,
     "grade_id": "ans_five",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ans_five():\n",
    "    \"\"\" Returns tuple of four numerical values of your linear model.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :a:  float\n",
    "        theta_0 from your fitted model \n",
    "    :b:  float\n",
    "        theta_1 from your fitted model \n",
    "    :c:  float\n",
    "        the last value of the array J_history \n",
    "    :d:  float\n",
    "         Akaike information criterion score, to 1 decimal place of precision\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    :a: 3.29168\n",
    "    :b: 3.73748\n",
    "    :c: 0.24686\n",
    "    :d: 332.3\n",
    "    \"\"\"\n",
    " \n",
    "    # YOUR CODE HERE\n",
    "    theta2, X2 = initialize(data2, 0.0,0.0) #y, m global\n",
    "    \n",
    "    #using sklearn\n",
    "    # instantiate model\n",
    "    model2 = LinearRegression()\n",
    "    \n",
    "    # fit the model\n",
    "    model2.fit(X2, y)\n",
    "    \n",
    "    #print theta0 and theta1\n",
    "    #print('theta_0:', model2.intercept_)\n",
    "    #print('theta_1:', model2.coef_[1])\n",
    "    \n",
    "    #using gradient descent -------\n",
    "    \n",
    "    # run gradient descent\n",
    "    theta2_new, J_history2 = batchGradientDescent(X2, y, theta2, alpha, 11000) #alpha = 0.2, iterations = 11000\n",
    "    #print('J_history2_last: ', J_history2[len(J_history2)-1])\n",
    "    #print('theta GD:', theta2_new) #-- theta new is different to 4dp with GD compared to LR\n",
    "    \n",
    "    # AIC \n",
    "    from statsmodels.api import OLS\n",
    "    m2 = OLS(y, X2).fit() #the AIC value was taken from these summary stats\n",
    "    #print(m2.aic) \n",
    "    \n",
    "    a = round(model2.intercept_, 5)\n",
    "    b = round(model2.coef_[1], 5)\n",
    "    c = round(J_history2[len(J_history2)-1], 5)\n",
    "    d = round(m2.aic,1)\n",
    "    \n",
    "    #print(a,b,c,d)\n",
    "    \n",
    "    \n",
    "    return a, b, c, d  # do not edit\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98e4714fc41d452057b1c21c708d2c54",
     "grade": true,
     "grade_id": "ans_five-test1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42b95c789cda8b7040443d1b90ac849f",
     "grade": true,
     "grade_id": "ans_five-test2",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b7083c0f193a6a6f32d3dbd6c72f221",
     "grade": true,
     "grade_id": "ans_five-test3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5e0148570e91820b04cd83f79d84dc0",
     "grade": true,
     "grade_id": "ans_five-test4",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfd9c23759b8e7705c5ceb8b438db650",
     "grade": true,
     "grade_id": "collaborator_policy_test",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Collaborator policy before submission\n",
    "%run -i 'collaboration_test.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da0aab92ebe963152ba50e5003048a73",
     "grade": false,
     "grade_id": "cell-3855ebc915820d81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before submitting this notebook, you should do the following steps:\n",
    "  \n",
    "  1. __Restart Kernel__ (Kernel âŸ¶ Restart and Clear Output)\n",
    "  2. __Run all Cells__ (Cell âŸ¶ Run All)\n",
    "  3. __Validate Notebook__: Press the 'Validate' button on this page. This is the first validation step.\n",
    "  4. __Save File__ (File âŸ¶ Save and Checkpoint)\n",
    "  5. __Close and Shutdown Kernel__ (File âŸ¶ Close and Halt)\n",
    "  \n",
    "Then, follow the final steps for submitting the assignment.\n",
    "\n",
    "  6. __Validate Submission__: On the submissions page, validate your assignment folder ps1. This is the second validation step. Your submissions is ready for submission only if it passes both the first and second validation steps.\n",
    "  7. __Submit__: Press the submission button to submit your validated assignment. The time stamp is the time of submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
